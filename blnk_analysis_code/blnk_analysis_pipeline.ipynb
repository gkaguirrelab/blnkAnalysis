{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e49c8fee",
   "metadata": {},
   "source": [
    "# BLNK Analysis Pipeline\n",
    "This notebook serves an interactive means to operate the BLNK extraction pipeline. Following the steps below, \n",
    "one may analyze videos of the eye and extract pupil and eyelids information therefrom, outputting the \n",
    "result as a MATLAB file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfac0e",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup and Library Imports\n",
    "To use the pipeline, one must first install [Pylids](https://github.com/piecesofmindlab/pylids), which is attached as a submodule to this GitHub repo. \n",
    "Follow their installation instructions first. This will generate a pylids conda environment you will use as the basis for this project into which\n",
    "we will install further libraries.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f75ec2",
   "metadata": {},
   "source": [
    "### Ensuring Correct Kernel\n",
    "To ensure you are using the correct pylids kernel, we will first import some standard library functions to check \n",
    "the name of the kernel you are using and assert it is the correct one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55afc87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pathlib\n",
    "import importlib\n",
    "from natsort import natsorted\n",
    "conda_kernel_name: str | None = os.environ.get(\"CONDA_DEFAULT_ENV\")\n",
    "assert conda_kernel_name == \"pylids\", f\"Conda environment: {conda_kernel_name} is not equal to pylids\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e639a69b",
   "metadata": {},
   "source": [
    "### Installing Additional Libraries. \n",
    "After the pylids conda environment has been created, we have to also install \n",
    "additional libraries into that environment used by this project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a0d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pupil-detectors\n",
    "%pip install pye3d\n",
    "%pip install natsort \n",
    "%pip install hdf5storage\n",
    "%pip install scipy \n",
    "%pip install dill\n",
    "%pip install h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ddede1",
   "metadata": {},
   "source": [
    "### Import Custom Libraries\n",
    "Next, we will import the custom libraries written to do the analysis for this pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94485105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc8...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the top level of htis repo \n",
    "blnk_analysis_dir: str = \"/Users/zacharykelly/Documents/MATLAB/projects/BLNK_pipeline\"\n",
    "assert os.path.exists(blnk_analysis_dir), f\"Path: {blnk_analysis_dir} does not exist\"\n",
    "sys.path.append(blnk_analysis_dir)\n",
    "\n",
    "from utility import video_io\n",
    "from blnk_analysis_code.utility import blnk_analysis_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb730537",
   "metadata": {},
   "source": [
    "## Step 2: Gather Paths to Videos for Analysis\n",
    "Now that our libraries are properly installed, we will not gather the path(s) to the videos that \n",
    "we would like to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f845d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will initialize the list of videos we want to analyze. \n",
    "# We will populate this list with either a single path or many paths later \n",
    "videos_to_analyze: list[str] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ccf09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to analyze a directory of videos, simply enter the path to that directory here \n",
    "video_directory_path: str = \"/Users/zacharykelly/Aguirre-Brainard Lab Dropbox/Zachary Kelly/BLNK_raw/PuffLight/modulate/BLNK_1001\"\n",
    "videos_to_analyze.extend([os.path.join(video_directory_path, filename) \n",
    "                          for filename in os.listdir(video_directory_path) if filename.endswith(\".avi\")]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180fdc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will assert that all paths are unique, exist and can be accessed (e.g. ensure they are local files if the directory is on DropBox)\n",
    "unique_videos_to_analyze: dict[str, None] = {video: None \n",
    "                                             for video in videos_to_analyze\n",
    "                                            } # We use a dictionary to preserve order as compared to set\n",
    "\n",
    "# After we have asserted that all of the videos are unique, let's ensure the paths exist and they can be accessed \n",
    "for path in unique_videos_to_analyze:\n",
    "    assert os.path.exists(path), f\"Path does not exist: {path}\"\n",
    "    try:\n",
    "        assert video_io.inspect_video_frame_count(path) != 0, f\"Frame count for path: {path} is 0\" \n",
    "    except:\n",
    "        raise Exception(f\"Cannot count frames for path: {path}. Check if the file is corrupted/online-only?\")\n",
    "    \n",
    "# Reassign videos to analyze to be the unique set \n",
    "videos_to_analyze = [video for video, _ in unique_videos_to_analyze.items()]\n",
    "assert len(videos_to_analyze) != 0, f\"No videos to analyze\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350a39be",
   "metadata": {},
   "source": [
    "## Step 3: Defining Output Location\n",
    "Next, we will define where the output of the analysis of the desired videos should be placed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc8d50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output folder \n",
    "output_folder_path: str = video_directory_path.replace(\"BLNK_raw\", \"BLNK_analysis\")\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "assert os.path.exists(output_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21172d44",
   "metadata": {},
   "source": [
    "## Step 4: Analyze Videos \n",
    "Now, we will analyze the desired videos. Doing so involves an intermediate step of modifying the video \n",
    "video cropping and then padding to a certain size, while also blacking out overly white pixels. Before analyzing, we must define the values of these parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a4219c",
   "metadata": {},
   "source": [
    "### Parameter Declaration\n",
    "\n",
    "First, we will define the aforementioned constant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the image manipulation parameters \n",
    "t, b, l, r = 0, 240, 0, 325\n",
    "crop_box: tuple = (t, b, l, r)\n",
    "target_size: tuple = (480, 640)\n",
    "whiteness_threshold: int = 200\n",
    "contrast: float = 1\n",
    "brightness: float = 0\n",
    "gamma: float = 1.2\n",
    "\n",
    "# Generate a temp output directory for the intermediate stage videos\n",
    "temp_dir_path: str = '/Users/zacharykelly/Desktop'\n",
    "if(not os.path.exists(temp_dir_path)):\n",
    "    os.mkdir(temp_dir_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b3e4eb",
   "metadata": {},
   "source": [
    "### Parameter Verification\n",
    "TODO: Explain this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a61b1f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with clang version 19.1.7\n",
      "  configuration: --prefix=/opt/anaconda3/envs/pylids --cc=arm64-apple-darwin20.0.0-clang --cxx=arm64-apple-darwin20.0.0-clang++ --nm=arm64-apple-darwin20.0.0-nm --ar=arm64-apple-darwin20.0.0-ar --disable-doc --enable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-cross-compile --arch=arm64 --target-os=darwin --cross-prefix=arm64-apple-darwin20.0.0- --host-cc=/Users/runner/miniforge3/conda-bld/ffmpeg_1753272244790/_build_env/bin/x86_64-apple-darwin13.4.0-clang --enable-neon --disable-gnutls --enable-libvpx --enable-libass --enable-pthreads --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libmp3lame --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libvorbis --enable-libopus --enable-librsvg --enable-ffplay --pkg-config=/Users/runner/miniforge3/conda-bld/ffmpeg_1753272244790/_build_env/bin/pkg-config\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, avi, from './temp_blnk_pipeline/temp_BLNK_1001_modulate_adapt-02_L.avi':\n",
      "  Metadata:\n",
      "    software        : Lavf61.7.100\n",
      "  Duration: 00:00:02.78, start: 0.000000, bitrate: 442501 kb/s\n",
      "  Stream #0:0: Video: rawvideo (Y800 / 0x30303859), gray, 640x480, 443254 kb/s, 180 fps, 180 tbr, 180 tbn\n",
      "[out#0/avi @ 0x157f08140] Error opening output ./temp2_blnk_pipeline/temp2_BLNK_1001_modulate_adapt-02_L.avi: No such file or directory\n",
      "Error opening output file ./temp2_blnk_pipeline/temp2_BLNK_1001_modulate_adapt-02_L.avi.\n",
      "Error opening output files: No such file or directory\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['ffmpeg', '-y', '-i', './temp_blnk_pipeline/temp_BLNK_1001_modulate_adapt-02_L.avi', '-vf', 'eq=contrast=1:brightness=0:gamma=1.2', '-c:a', 'copy', './temp2_blnk_pipeline/temp2_BLNK_1001_modulate_adapt-02_L.avi']' returned non-zero exit status 254.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCalledProcessError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 24\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Determine if we should visiualize the results.\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# That is, we will only visualize dark and adapt videos \u001b[39;00m\n\u001b[1;32m     23\u001b[0m video_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(video_path\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[0;32m---> 24\u001b[0m \u001b[43mblnk_analysis_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_eye_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_dir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mthreshold_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhiteness_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mvisualize_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43moverrwrite_existing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mdebug_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcontrast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mbrightness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbrightness\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m                                           \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MATLAB/projects/BLNK_pipeline/blnk_analysis_code/utility/blnk_analysis_pipeline.py:93\u001b[0m, in \u001b[0;36mpredict_eye_features\u001b[0;34m(filepath, output_folder_path, crop_box, target_size, temp_dir_path, threshold_value, visualize_results, overrwrite_existing, contrast, gamma, brightness, debug_mode)\u001b[0m\n\u001b[1;32m     90\u001b[0m     video_resized \u001b[38;5;241m=\u001b[39m video_resized[:\u001b[38;5;241m500\u001b[39m]\n\u001b[1;32m     92\u001b[0m video_io\u001b[38;5;241m.\u001b[39mframes_to_video(video_resized, temp_video_path, video_fps)\n\u001b[0;32m---> 93\u001b[0m \u001b[43mapply_ffmpeg_contrast_gamma\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemp_video_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_video_path_step2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontrast\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontrast\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrightness\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbrightness\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m os\u001b[38;5;241m.\u001b[39mreplace(temp_video_path_step2, temp_video_path)\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# Display the transfomred image if desired\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# If we want to visualize, we will display what the thresholding and cropping looks like \u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MATLAB/projects/BLNK_pipeline/blnk_analysis_code/utility/blnk_analysis_pipeline.py:171\u001b[0m, in \u001b[0;36mapply_ffmpeg_contrast_gamma\u001b[0;34m(input_path, output_path, contrast, gamma, brightness)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mapply_ffmpeg_contrast_gamma\u001b[39m(input_path: \u001b[38;5;28mstr\u001b[39m, output_path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    161\u001b[0m                                 contrast: \u001b[38;5;28mfloat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, gamma: \u001b[38;5;28mfloat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m, brightness: \u001b[38;5;28mfloat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    162\u001b[0m                                ):\n\u001b[1;32m    163\u001b[0m     cmd: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]\u001b[38;5;241m=\u001b[39m [ \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mffmpeg\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    164\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-y\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;66;03m# overwrite\u001b[39;00m\n\u001b[1;32m    165\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-i\u001b[39m\u001b[38;5;124m\"\u001b[39m, input_path,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    168\u001b[0m                       output_path\n\u001b[1;32m    169\u001b[0m                     ]\n\u001b[0;32m--> 171\u001b[0m     \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/pylids/lib/python3.10/subprocess.py:526\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    524\u001b[0m     retcode \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mpoll()\n\u001b[1;32m    525\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[0;32m--> 526\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process\u001b[38;5;241m.\u001b[39margs,\n\u001b[1;32m    527\u001b[0m                                  output\u001b[38;5;241m=\u001b[39mstdout, stderr\u001b[38;5;241m=\u001b[39mstderr)\n\u001b[1;32m    528\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process\u001b[38;5;241m.\u001b[39margs, retcode, stdout, stderr)\n",
      "\u001b[0;31mCalledProcessError\u001b[0m: Command '['ffmpeg', '-y', '-i', './temp_blnk_pipeline/temp_BLNK_1001_modulate_adapt-02_L.avi', '-vf', 'eq=contrast=1:brightness=0:gamma=1.2', '-c:a', 'copy', './temp2_blnk_pipeline/temp2_BLNK_1001_modulate_adapt-02_L.avi']' returned non-zero exit status 254."
     ]
    }
   ],
   "source": [
    "importlib.reload(blnk_analysis_pipeline)\n",
    "\n",
    "# First, we will visualize the first few seconds of only a few dark and adapt videos\n",
    "# from each DATE for this participant to \n",
    "\n",
    "adapt_verification_videos: list[str] = [filepath\n",
    "                                        for filepath in videos_to_analyze \n",
    "                                        if \"adapt\" in os.path.basename(filepath.rstrip(\"/\"))\n",
    "                                       ][::4]\n",
    "dark_verification_videos: list[str] = [filepath\n",
    "                                       for filepath in videos_to_analyze \n",
    "                                       if \"dark\" in os.path.basename(filepath.rstrip(\"/\")) \n",
    "                                      ][::4] \n",
    "\n",
    "verification_videos = adapt_verification_videos + dark_verification_videos\n",
    "\n",
    "# Iterate over the videos and output them to the target directory \n",
    "for video_num, video_path in enumerate(verification_videos):\n",
    "    print(f\"Processing video: {video_num+1}/{len(verification_videos)}\", flush=True)\n",
    "\n",
    "    # Determine if we should visiualize the results.\n",
    "    # That is, we will only visualize dark and adapt videos \n",
    "    video_name: str = os.path.basename(video_path.rstrip(\"/\"))\n",
    "    blnk_analysis_pipeline.predict_eye_features(video_path, output_folder_path, crop_box, target_size, temp_dir_path, \n",
    "                                                threshold_value=whiteness_threshold,\n",
    "                                                visualize_results=True,\n",
    "                                                overrwrite_existing=True,\n",
    "                                                debug_mode=True,\n",
    "                                                contrast=contrast,\n",
    "                                                gamma=gamma,\n",
    "                                                brightness=brightness\n",
    "                                               )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf3550c",
   "metadata": {},
   "source": [
    "### Analysis\n",
    "Once you are satisfied with the above parameters , we can move onto analyzing the target video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad5de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(blnk_analysis_pipeline)\n",
    "\n",
    "# Iterate over the videos and output them to the target directory \n",
    "for video_num, video_path in enumerate(videos_to_analyze):\n",
    "    print(f\"Processing video: {video_num+1}/{len(videos_to_analyze)}\", flush=True)\n",
    "\n",
    "    # Determine if we should visiualize the results.\n",
    "    # That is, we will only visualize dark and adapt videos \n",
    "    video_name: str = os.path.basename(video_path.rstrip(\"/\"))\n",
    "    blnk_analysis_pipeline.predict_eye_features(video_path, output_folder_path, crop_box, target_size, temp_dir_path, \n",
    "                                                threshold_value=whiteness_threshold,\n",
    "                                                visualize_results=False,\n",
    "                                                overrwrite_existing=False\n",
    "                                               )\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6647da47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
