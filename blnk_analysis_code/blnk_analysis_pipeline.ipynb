{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e49c8fee",
   "metadata": {},
   "source": [
    "# BLNK Analysis Pipeline\n",
    "This notebook serves an interactive means to operate the BLNK extraction pipeline. Following the steps below, \n",
    "one may analyze videos of the eye and extract pupil and eyelids information therefrom, outputting the \n",
    "result as a MATLAB file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfac0e",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup and Library Imports\n",
    "To use the pipeline, one must first install [Pylids](https://github.com/piecesofmindlab/pylids), which is attached as a submodule to this GitHub repo. \n",
    "Follow their installation instructions first. This will generate a pylids conda environment you will use as the basis for this project into which\n",
    "we will install further libraries.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f75ec2",
   "metadata": {},
   "source": [
    "### Ensuring Correct Kernel\n",
    "To ensure you are using the correct pylids kernel, we will first import some standard library functions to check \n",
    "the name of the kernel you are using and assert it is the correct one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55afc87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pathlib\n",
    "import importlib\n",
    "conda_kernel_name: str | None = os.environ.get(\"CONDA_DEFAULT_ENV\")\n",
    "assert conda_kernel_name == \"pylids\", f\"Conda environment: {conda_kernel_name} is not equal to pylids\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e639a69b",
   "metadata": {},
   "source": [
    "### Installing Additional Libraries. \n",
    "After the pylids conda environment has been created, we have to also install \n",
    "additional libraries into that environment used by this project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a0d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pupil-detectors\n",
    "%pip install pye3d\n",
    "%pip install natsort \n",
    "%pip install hdf5storage\n",
    "%pip install scipy \n",
    "%pip install dill\n",
    "%pip install h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ddede1",
   "metadata": {},
   "source": [
    "### Import Custom Libraries\n",
    "Next, we will import the custom libraries written to do the analysis for this pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94485105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc8...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the top level of htis repo \n",
    "blnk_analysis_dir: str = \"/Users/zacharykelly/Documents/MATLAB/projects/BLNK_pipeline\"\n",
    "assert os.path.exists(blnk_analysis_dir), f\"Path: {blnk_analysis_dir} does not exist\"\n",
    "sys.path.append(blnk_analysis_dir)\n",
    "\n",
    "from utility import video_io\n",
    "from blnk_analysis_code.utility import blnk_analysis_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb730537",
   "metadata": {},
   "source": [
    "## Step 2: Gather Paths to Videos for Analysis\n",
    "Now that our libraries are properly installed, we will not gather the path(s) to the videos that \n",
    "we would like to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f845d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will initialize the list of videos we want to analyze. \n",
    "# We will populate this list with either a single path or many paths later \n",
    "videos_to_analyze: list[str] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbfa83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you simly want to analyze a single video, enter the path to the \n",
    "# video directory here \n",
    "single_video_path: str = \"/Users/zacharykelly/Aguirre-Brainard Lab Dropbox/Zachary Kelly/BLNK_raw/PuffLight/modulate/TEST_001/TEST_001_modulate_direction-Mel_contrast-0.40_phase-3.14_trial-001_dual.avi\"\n",
    "videos_to_analyze.append(single_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ccf09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to analyze a directory of videos, simply enter the path to that directory here \n",
    "video_directory_path: str = \"/Users/zacharykelly/Aguirre-Brainard Lab Dropbox/Zachary Kelly/BLNK_raw/PuffLight/modulate/BLNK_1001\"\n",
    "videos_to_analyze.extend([os.path.join(video_directory_path, filename) \n",
    "                          for filename in os.listdir(video_directory_path) if filename.endswith(\".avi\")]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180fdc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will assert that all paths are unique, exist and can be accessed (e.g. ensure they are local files if the directory is on DropBox)\n",
    "unique_videos_to_analyze: dict[str, None] = {video: None \n",
    "                                             for video in videos_to_analyze\n",
    "                                            } # We use a dictionary to preserve order as compared to set\n",
    "\n",
    "# After we have asserted that all of the videos are unique, let's ensure the paths exist and they can be accessed \n",
    "for path in unique_videos_to_analyze:\n",
    "    assert os.path.exists(path), f\"Path does not exist: {path}\"\n",
    "    try:\n",
    "        assert video_io.inspect_video_frame_count(path) != 0, f\"Frame count for path: {path} is 0\" \n",
    "    except:\n",
    "        raise Exception(f\"Cannot count frames for path: {path}. Check if the file is corrupted/online-only?\")\n",
    "    \n",
    "# Reassign videos to analyze to be the unique set \n",
    "videos_to_analyze = [video for video, _ in unique_videos_to_analyze.items()]\n",
    "assert len(videos_to_analyze) != 0, f\"No videos to analyze\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350a39be",
   "metadata": {},
   "source": [
    "## Step 3: Defining Output Location\n",
    "Next, we will define where the output of the analysis of the desired videos should be placed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc8d50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output folder \n",
    "output_folder_path: str = \"/Users/zacharykelly/Aguirre-Brainard Lab Dropbox/Zachary Kelly/BLNK_analysis/PuffLight/modulate/BLNK_1001\"\n",
    "os.makedirs(output_folder_path, exist_ok=True)\n",
    "assert os.path.exists(output_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21172d44",
   "metadata": {},
   "source": [
    "## Step 4: Analyze Videos \n",
    "Now, we will analyze the desired videos. Doing so involves an intermediate step of modifying the video \n",
    "video cropping and then padding to a certain size, while also blacking out overly white pixels. Before analyzing, we must define the values of these parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a4219c",
   "metadata": {},
   "source": [
    "### Parameter Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6549b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the crop box and target size \n",
    "t, b, l, r = 0, 240, 0, 325\n",
    "crop_box: tuple = (t, b, l, r)\n",
    "target_size: tuple = (480, 640)\n",
    "whiteness_threshold: int = 225\n",
    "\n",
    "# Generate a temp output directory for the intermediate stage videos\n",
    "temp_dir_path: str = './temp_blnk_pipeline'\n",
    "if(not os.path.exists(temp_dir_path)):\n",
    "    os.mkdir(temp_dir_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf3550c",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dad5de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: 1/38\n",
      "/Users/zacharykelly/Aguirre-Brainard Lab Dropbox/Zachary Kelly/BLNK_analysis/PuffLight/modulate/BLNK_1001/BLNK_1001_modulate_direction-Mel_contrast-0.40_phase-0.00_trial-002_L_eyeFeatures.mat\n",
      "/Users/zacharykelly/Aguirre-Brainard Lab Dropbox/Zachary Kelly/BLNK_analysis/PuffLight/modulate/BLNK_1001/BLNK_1001_modulate_direction-Mel_contrast-0.40_phase-0.00_trial-002_R_eyeFeatures.mat\n",
      "Processing video: 2/38\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video_num, video_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(videos_to_analyze):\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing video: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvideo_num\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(videos_to_analyze)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mblnk_analysis_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_eye_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcrop_box\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemp_dir_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mthreshold_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhiteness_threshold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mvisualize_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43moverrwrite_existing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                               \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MATLAB/projects/BLNK_pipeline/blnk_analysis_code/utility/blnk_analysis_pipeline.py:38\u001b[0m, in \u001b[0;36mpredict_eye_features\u001b[0;34m(filepath, output_folder_path, crop_box, target_size, temp_dir_path, threshold_value, visualize_results, overrwrite_existing)\u001b[0m\n\u001b[1;32m     35\u001b[0m video_fps: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m=\u001b[39m video_io\u001b[38;5;241m.\u001b[39minspect_video_FPS(filepath)\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Videos are small, so we can load them entirely in from memory \u001b[39;00m\n\u001b[0;32m---> 38\u001b[0m video_as_arr: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m \u001b[43mvideo_io\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdestruct_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grayscale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Note: A given BLNK video is composed of 2 independent \u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# videos of L and R eyes joined at the middle. They are \u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# the same size originally image wise, so first, we must split them \u001b[39;00m\n\u001b[1;32m     43\u001b[0m width_midpoint: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m video_as_arr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n",
      "File \u001b[0;32m~/Documents/MATLAB/projects/BLNK_pipeline/blnk_analysis_code/utility/video_io.py:291\u001b[0m, in \u001b[0;36mdestruct_video\u001b[0;34m(video_path, start_frame, end_frame, is_grayscale, q, stop_event)\u001b[0m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# Stream the frames in from the vidoe \u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m(frame_num \u001b[38;5;241m<\u001b[39m end_frame):\n\u001b[1;32m    290\u001b[0m     \u001b[38;5;66;03m# Jump the the target frame in the stream\u001b[39;00m\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mvideo_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCAP_PROP_POS_FRAMES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframe_num\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;66;03m# Attempt to read in a video \u001b[39;00m\n\u001b[1;32m    294\u001b[0m     \u001b[38;5;66;03m# from the stream \u001b[39;00m\n\u001b[1;32m    295\u001b[0m     ret, frame \u001b[38;5;241m=\u001b[39m video_stream\u001b[38;5;241m.\u001b[39mread() \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "importlib.reload(blnk_analysis_pipeline)\n",
    "\n",
    "# Iterate over the videos and output them to the target directory \n",
    "for video_num, video_path in enumerate(videos_to_analyze):\n",
    "    print(f\"Processing video: {video_num+1}/{len(videos_to_analyze)}\", flush=True)\n",
    "    blnk_analysis_pipeline.predict_eye_features(video_path, output_folder_path, crop_box, target_size, temp_dir_path, \n",
    "                                                threshold_value=whiteness_threshold,\n",
    "                                                visualize_results=False,\n",
    "                                                overrwrite_existing=False\n",
    "                                               )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac455f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "dropbox_dir: str = \"/Users/zacharykelly/Aguirre-Brainard Lab Dropbox/Zachary Kelly/BLNK_analysis/PuffLight/modulate\"\n",
    "\n",
    "for folder_path in os.listdir(dropbox_dir):\n",
    "    if(\"BLNK\" not in file):\n",
    "        continue\n",
    "    \n",
    "    fi\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
