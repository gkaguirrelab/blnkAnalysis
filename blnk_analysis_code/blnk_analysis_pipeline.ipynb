{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e49c8fee",
   "metadata": {},
   "source": [
    "# BLNK Analysis Pipeline\n",
    "This notebook serves an interactive means to operate the BLNK extraction pipeline. Following the steps below, \n",
    "one may analyze videos of the eye and extract pupil and eyelids information therefrom, outputting the \n",
    "result as a MATLAB file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdfac0e",
   "metadata": {},
   "source": [
    "## Step 1: Environment Setup and Library Imports\n",
    "To use the pipeline, one must first install [Pylids](https://github.com/piecesofmindlab/pylids), which is attached as a submodule to this GitHub repo. \n",
    "Follow their installation instructions first. This will generate a pylids conda environment you will use as the basis for this project into which\n",
    "we will install further libraries.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f75ec2",
   "metadata": {},
   "source": [
    "### Ensuring Correct Kernel\n",
    "To ensure you are using the correct pylids kernel, we will first import some standard library functions to check \n",
    "the name of the kernel you are using and assert it is the correct one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55afc87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import pathlib\n",
    "conda_kernel_name: str | None = os.environ.get(\"CONDA_DEFAULT_ENV\")\n",
    "assert conda_kernel_name == \"pylids\", f\"Conda environment: {conda_kernel_name} is not equal to pylids\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e639a69b",
   "metadata": {},
   "source": [
    "### Installing Additional Libraries. \n",
    "After the pylids conda environment has been created, we have to also install \n",
    "additional libraries into that environment used by this project "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a0d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pupil-detectors\n",
    "%pip install pye3d\n",
    "%pip install natsort \n",
    "%pip install hdf5storage\n",
    "%pip install scipy \n",
    "%pip install dill\n",
    "%pip install h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ddede1",
   "metadata": {},
   "source": [
    "### Import Custom Libraries\n",
    "Next, we will import the custom libraries written to do the analysis for this pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94485105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 3.0.0rc8...\n",
      "DLC loaded in light mode; you cannot use any GUI (labeling, relabeling and standalone GUI)\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the top level of htis repo \n",
    "blnk_analysis_dir: str = \"/Users/zacharykelly/Documents/MATLAB/projects/BLNK_pipeline\"\n",
    "assert os.path.exists(blnk_analysis_dir), f\"Path: {blnk_analysis_dir} does not exist\"\n",
    "sys.path.append(blnk_analysis_dir)\n",
    "\n",
    "from utility import video_io\n",
    "from blnk_analysis_code.utility import blnk_analysis_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb730537",
   "metadata": {},
   "source": [
    "## Step 2: Gather Paths to Videos for Analysis\n",
    "Now that our libraries are properly installed, we will not gather the path(s) to the videos that \n",
    "we would like to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f845d110",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we will initialize the list of videos we want to analyze. \n",
    "# We will populate this list with either a single path or many paths later \n",
    "videos_to_analyze: list[str] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fbfa83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you simly want to analyze a single video, enter the path to the \n",
    "# video directory here \n",
    "single_video_path: str = \"/Users/zacharykelly/Aguirre-Brainard Lab Dropbox/Zachary Kelly/BLNK_raw/PuffLight/modulate/TEST_001/TEST_001_modulate_direction-Mel_contrast-0.40_phase-3.14_trial-001_dual.avi\"\n",
    "videos_to_analyze.append(single_video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ccf09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to analyze a directory of videos, simply enter the path to that directory here \n",
    "video_directory_path: str = \"/Users/zacharykelly/Aguirre-Brainard Lab Dropbox/Zachary Kelly/BLNK_raw/PuffLight/modulate/TEST_001\"\n",
    "videos_to_analyze.extend([os.path.join(video_directory_path, filename) \n",
    "                          for filename in os.listdir(video_directory_path) if filename.endswith(\".avi\")]\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "180fdc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will assert that all paths are unique, exist and can be accessed (e.g. ensure they are local files if the directory is on DropBox)\n",
    "unique_videos_to_analyze: dict[str, None] = {video: None \n",
    "                                             for video in videos_to_analyze\n",
    "                                            } # We use a dictionary to preserve order as compared to set\n",
    "\n",
    "# After we have asserted that all of the videos are unique, let's ensure the paths exist and they can be accessed \n",
    "for path in unique_videos_to_analyze:\n",
    "    assert os.path.exists(path), f\"Path does not exist: {path}\"\n",
    "    try:\n",
    "        assert video_io.inspect_video_frame_count(path) != 0, f\"Frame count for path: {path} is 0\" \n",
    "    except:\n",
    "        raise Exception(f\"Cannot count frames for path: {path}. Check if the file is corrupted/online-only?\")\n",
    "    \n",
    "# Reassign videos to analyze to be the unique set \n",
    "videos_to_analyze = [video for video, _ in unique_videos_to_analyze.items()]\n",
    "assert len(videos_to_analyze) != 0, f\"No videos to analyze\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350a39be",
   "metadata": {},
   "source": [
    "## Step 3: Defining Output Location\n",
    "Next, we will define where the output of the analysis of the desired videos should be placed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8d50a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate output folder \n",
    "output_folder_path: str = \"/Users/zacharykelly/Aguirre-Brainard Lab Dropbox/Zachary Kelly/BLNK_analysis/PuffLight/modulate/TEST_001\"\n",
    "os.makedirs(output_folder_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21172d44",
   "metadata": {},
   "source": [
    "## Step 4: Analyze Videos \n",
    "Now, we will analyze the desired videos. Doing so involves an intermediate step of modifying the video \n",
    "video cropping and then padding to a certain size, while also blacking out overly white pixels. Before analyzing, we must define the values of these parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a4219c",
   "metadata": {},
   "source": [
    "### Parameter Declaration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549b784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the crop box and target size \n",
    "t, b, l, r = 140, 275, 190, 425\n",
    "crop_box: tuple = (t, b, l, r)\n",
    "target_size: tuple = (480, 640)\n",
    "whiteness_threshold: int = 225\n",
    "\n",
    "# Generate a temp output directory for the intermediate stage videos\n",
    "temp_dir_path: str = './temp_blnk_pipeline'\n",
    "if(not os.path.exists(temp_dir_path)):\n",
    "    os.mkdir(temp_dir_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf3550c",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dad5de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the videos and output them to the target directory \n",
    "for video_num, video_path in enumerate(videos_to_analyze):\n",
    "    print(f\"Processing video: {video_num+1}/{len(videos_to_analyze)}\", flush=True)\n",
    "    blnk_analysis_pipeline.predict_eye_features(video_path, output_folder_path, crop_box, target_size, temp_dir_path, \n",
    "                                                threshold_value=whiteness_threshold\n",
    "                                               )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f2fdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylids",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
